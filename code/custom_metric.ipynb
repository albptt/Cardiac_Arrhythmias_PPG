{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV06WGRYETjM"
      },
      "source": [
        "# Custom Metric: Penalized Sensitivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2XcJCsYEgN8"
      },
      "source": [
        "## Two Class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiejjhZFES9c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "def penalized_sensitivity_binary_metric(y_true, y_pred, threshold=0.9, penalty=None):\n",
        "    # Calculate recall for each class\n",
        "    recall = recall_score(y_true, y_pred, average=None)\n",
        "\n",
        "    # If the recall for 'Normal' beats is below the threshold, return penalized recall for 'Abnormal' beats\n",
        "    if recall[0] < threshold:\n",
        "        if penalty is None:\n",
        "            penalty = recall[0]\n",
        "        return round(recall[1]*penalty,2)\n",
        "\n",
        "    # Otherwise, return the recall for 'Abnormal' beats\n",
        "    return recall[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srF8CARaEinO"
      },
      "source": [
        "## Three class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezcWOX69EkoC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "def penalized_sensitivity_threeclass_metric(y_true, y_pred, threshold=0.9, penalty=None):\n",
        "    # Calculate recall for each class\n",
        "    recall = recall_score(y_true, y_pred, average=None)\n",
        "\n",
        "    # Compute the average of the 'S' and 'V' recalls\n",
        "    avg_recall_sv = round((recall[1] + recall[2]) / 2,2)\n",
        "\n",
        "    # If the recall for 'N' beats is below the threshold, return penalized normalized recall for 'S' and 'V'\n",
        "    if recall[0] < threshold:\n",
        "        if penalty is None:\n",
        "            penalty = recall[0]\n",
        "        return round(avg_recall_sv*penalty,2)\n",
        "\n",
        "    # Otherwise, return the normalized sum of recall for 'S' and 'V' beats\n",
        "    return avg_recall_sv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83odw_SyEmj4"
      },
      "source": [
        "# Use custom metric as scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v42dugaqEoLG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Create a custom scorer\n",
        "custom_scorer_binary = make_scorer(penalized_sensitivity_binary_metric, greater_is_better=True)\n",
        "custom_scorer_threeclass = make_scorer(penalized_sensitivity_threeclass_metric, greater_is_better=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
