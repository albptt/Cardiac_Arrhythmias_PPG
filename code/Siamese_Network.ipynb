{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TN9rKvunAXF"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "\n",
        "# Load the data with pickle\n",
        "with open('X_train_single', 'rb') as f:\n",
        "    X_train_single = pkl.load(f)\n",
        "with open('y_train_single', 'rb') as f:\n",
        "    y_train_single = pkl.load(f)\n",
        "with open('X_test_single', 'rb') as f:\n",
        "    X_test_single = pkl.load(f)\n",
        "with open('y_test_single', 'rb') as f:\n",
        "    y_test_single = pkl.load(f)\n",
        "with open('X_val_single', 'rb') as f:\n",
        "    X_val_single = pkl.load(f)\n",
        "with open('y_val_single', 'rb') as f:\n",
        "    y_val_single = pkl.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjgH0tVgx7qu"
      },
      "source": [
        "# Pair Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68DzNLU9lbhB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, Dropout, GlobalAveragePooling1D, Dense, Lambda, Bidirectional, LSTM, TimeDistributed, Flatten, BatchNormalization\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlGx_VzwyAnX"
      },
      "outputs": [],
      "source": [
        "# Beat pairs creation with label\n",
        "def create_pairs(beat, labels):\n",
        "  labelPairs = []\n",
        "  baseBeat = []\n",
        "  comparedBeat = []\n",
        "\n",
        "  #Getting the indices of each class\n",
        "  numclasses = len(np.unique(labels))\n",
        "  idx = [np.where(labels ==i)[0] for i in range(numclasses)]\n",
        "\n",
        "  for ind in range(len(beat)):\n",
        "    #Getting current beat with index\n",
        "    currBeat = beat[ind]\n",
        "    #getting the label of the beat from labels.\n",
        "    label = labels[ind]\n",
        "\n",
        "    #Randomly choosing another labels from the same class\n",
        "    indB = np.random.choice(idx[label])\n",
        "    #corresponding beat for this randomly selected label\n",
        "    indBeat = beat[indB]\n",
        "\n",
        "    baseBeat.append(currBeat)\n",
        "    comparedBeat.append(indBeat)\n",
        "\n",
        "\n",
        "    labelPairs.append([1])\n",
        "\n",
        "\n",
        "    #Getting a label where label is different than the current beat\n",
        "    diss_idx = np.where(labels != label)[0]\n",
        "\n",
        "    #finding a beat for this label\n",
        "    diss_beat = beat[np.random.choice(diss_idx)]\n",
        "\n",
        "    baseBeat.append(currBeat)\n",
        "    comparedBeat.append(diss_beat)\n",
        "    labelPairs.append([0])\n",
        "\n",
        "  return np.array(baseBeat), np.array(comparedBeat), np.array(labelPairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKC7W26e22LV"
      },
      "outputs": [],
      "source": [
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# Fit and transform the string labels to integer labels\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_single)\n",
        "y_val_encoded = label_encoder.fit_transform(y_val_single)\n",
        "y_test_encoded = label_encoder.fit_transform(y_test_single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gF0FVLsyXfo"
      },
      "outputs": [],
      "source": [
        "# training and validation pairs creation\n",
        "training_pairs_base, training_pairs_comp, training_labels = create_pairs(X_train_single, y_train_encoded)\n",
        "val_pairs_base, val_pairs_comp, val_labels = create_pairs(X_val_single, y_val_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFQsYQC85gj4"
      },
      "outputs": [],
      "source": [
        "# Define Loss function\n",
        "def contrastiveLoss(y, y_preds, margin=1):\n",
        " y = tf.cast(y, y_preds.dtype)\n",
        " y_preds_squared = K.square(y_preds)\n",
        " margin_squared = K.square(K.maximum(margin - y_preds, 0))\n",
        " loss = K.mean(y * y_preds_squared + (1 - y) * margin_squared)\n",
        " return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1Aym6DjmDAi"
      },
      "outputs": [],
      "source": [
        "# Define distance metric\n",
        "def euclidean_distance(vecs):\n",
        "    beatA, beatB = vecs\n",
        "    ss = K.sum(K.square(beatA - beatB), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(ss, K.epsilon()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmDseTDkmr2p"
      },
      "source": [
        "# Convolutional Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-iUL_fpgFYt"
      },
      "outputs": [],
      "source": [
        "# Definition of siamese model based on Convolutional layers\n",
        "def siamese_model(input_shape, embeddingDim=48):\n",
        "    inputs = Input(input_shape)\n",
        "    x = Conv1D(128, 2, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    # Trying a deeper model\n",
        "    x = Conv1D(256, 2, padding=\"same\", activation=\"relu\")(x)  # Additional Conv1D layer\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    pooling = GlobalAveragePooling1D()(x)\n",
        "    outputs = Dense(embeddingDim)(pooling)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1Z0woH8l6DJ"
      },
      "outputs": [],
      "source": [
        "beat_shape = (100, 1)\n",
        "batch_size = 1024\n",
        "epochs = 50\n",
        "\n",
        "beatA = Input(shape=beat_shape)\n",
        "beatB = Input(shape=beat_shape)\n",
        "\n",
        "model_build = siamese_model(beat_shape)\n",
        "beatA_embedding = model_build(beatA)\n",
        "beatB_embedding = model_build(beatB)\n",
        "\n",
        "distance = Lambda(euclidean_distance)([beatA_embedding, beatB_embedding])\n",
        "model = Model(inputs=[beatA, beatB], outputs=distance)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft4RdEhJmolT"
      },
      "source": [
        "# BiLSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t34wbQ2xxK2o",
        "outputId": "7946dff3-ed6f-4ba5-8f34-26c43994f69c"
      },
      "outputs": [],
      "source": [
        "# Definition of siamese model based on BiLSTM layer\n",
        "def siamese_model(input_shape, embeddingDim=48):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Replace Conv1D with Bidirectional LSTM\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(inputs)\n",
        "\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    outputs = Dense(embeddingDim)(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJVeXVS7miZs"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "beat_shape = (100, 1)\n",
        "batch_size = 1024\n",
        "epochs = 50\n",
        "\n",
        "beatA = Input(shape=beat_shape)\n",
        "beatB = Input(shape=beat_shape)\n",
        "\n",
        "model_build = siamese_model(beat_shape)\n",
        "beatA_embedding = model_build(beatA)\n",
        "beatB_embedding = model_build(beatB)\n",
        "\n",
        "distance = Lambda(euclidean_distance)([beatA_embedding, beatB_embedding])\n",
        "model = Model(inputs=[beatA, beatB], outputs=distance)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btnalKh-8ZTU"
      },
      "outputs": [],
      "source": [
        "# Compile the model with the contrastive loss function\n",
        "model.compile(loss = contrastiveLoss, optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdjkJZ5eZKAN"
      },
      "outputs": [],
      "source": [
        "# Change dimensionality to required format\n",
        "x_train_expand = np.expand_dims(training_pairs_base, axis = -1)\n",
        "x_train_c_expand = np.expand_dims(training_pairs_comp, axis = -1)\n",
        "\n",
        "x_val_expand = np.expand_dims(val_pairs_base, axis = -1)\n",
        "x_val_c_expand = np.expand_dims(val_pairs_comp, axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xjmVHZEHASb"
      },
      "outputs": [],
      "source": [
        "# Define early stopping callback\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 30, start_from_epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JWAJj-Y8U_N",
        "outputId": "8dad1d4c-9e14-4bdb-bdd0-5217699036a4"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    [x_train_expand, x_train_c_expand], training_labels,\n",
        "    validation_data=([x_val_expand, x_val_c_expand], val_labels),\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks=[early_stop]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3ibie7_hdrG"
      },
      "source": [
        "# Model Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgyTBCtbm2rW"
      },
      "source": [
        "Definition of a template for comparison and perform prediction on test set in the fastest possible way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF1gKBIBhiSq",
        "outputId": "791f10a2-dada-40ee-cda3-af1b1c42e29b"
      },
      "outputs": [],
      "source": [
        "# Extract beats from training set\n",
        "label_0_indices = np.where(y_train_encoded == 0)[0]\n",
        "label_1_indices = np.where(y_train_encoded == 1)[0]\n",
        "label_2_indices = np.where(y_train_encoded == 2)[0]\n",
        "\n",
        "X_train_N = X_train_single[label_0_indices]\n",
        "X_train_S = X_train_single[label_1_indices]\n",
        "X_train_V = X_train_single[label_2_indices]\n",
        "\n",
        "len(X_train_N),len(X_train_S),len(X_train_V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zokB2n1gi-FY",
        "outputId": "1c75a0db-1dca-45ab-df53-ab698a0b8107"
      },
      "outputs": [],
      "source": [
        "X_train_N_expanded = np.expand_dims(X_train_N, axis=-1)\n",
        "X_train_S_expanded = np.expand_dims(X_train_S, axis=-1)\n",
        "X_train_V_expanded = np.expand_dims(X_train_V, axis=-1)\n",
        "# Check the shape of the expanded data\n",
        "X_train_N_expanded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UiQsAeXi-FY",
        "outputId": "e656ac7e-6ffc-4b4a-952e-69e19c085cdf"
      },
      "outputs": [],
      "source": [
        "X_train_N_expanded_list = X_train_N_expanded.tolist()\n",
        "X_train_S_expanded_list = X_train_S_expanded.tolist()\n",
        "X_train_V_expanded_list = X_train_V_expanded.tolist()\n",
        "# Check the length of the list\n",
        "len(X_train_N_expanded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEJqkaMafZ-J"
      },
      "outputs": [],
      "source": [
        "def generate_template(beats_list):\n",
        "\n",
        "    # Stack the beats along a new axis (axis=0)\n",
        "    stacked_beats = np.stack(beats_list, axis=0)\n",
        "\n",
        "    # Compute the mean or median along the first axis (axis=0) to get the template\n",
        "    # template_beat = np.mean(stacked_beats, axis=0)\n",
        "    # Alternatively, you can use median\n",
        "    template_beat = np.median(stacked_beats, axis=0)\n",
        "\n",
        "    return template_beat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jfk7yCxjW_A"
      },
      "outputs": [],
      "source": [
        "# Generate the template for each class\n",
        "template_N = generate_template(X_train_N_expanded_list)\n",
        "template_S = generate_template(X_train_S_expanded_list)\n",
        "template_V = generate_template(X_train_V_expanded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "32AnvtI6gNvi",
        "outputId": "246b1ef4-84b0-43c7-85c6-842b6a73db4e"
      },
      "outputs": [],
      "source": [
        "# Visualize the templates\n",
        "plt.plot(template_N)\n",
        "plt.plot(template_S)\n",
        "plt.plot(template_V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXtiI2skndwl",
        "outputId": "04149dea-ec81-4fd4-ee6e-6c347322e787"
      },
      "outputs": [],
      "source": [
        "# Duplicate template to match the length of the test set\n",
        "ref_len = len(X_test_single)\n",
        "template_N_copied = np.tile(template_N, (ref_len, 1, 1))\n",
        "template_S_copied = np.tile(template_S, (ref_len, 1, 1))\n",
        "template_V_copied = np.tile(template_V, (ref_len, 1, 1))\n",
        "\n",
        "template_N_copied.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYCPTqVEnnmS",
        "outputId": "3dd1011c-6cf1-465f-8933-7cafe54f2335"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "prediction_N = model.predict([template_N_copied, X_test_single])\n",
        "prediction_S = model.predict([template_S_copied, X_test_single])\n",
        "prediction_V = model.predict([template_V_copied, X_test_single])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dBgAllwo6fT",
        "outputId": "37b4d78c-9abe-46d4-ce6c-85fdc03fdb00"
      },
      "outputs": [],
      "source": [
        "Prediction = np.concatenate([prediction_N, prediction_S, prediction_V], axis=1)\n",
        "# Check the shape of the prediction\n",
        "Prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj1M4n_aqj3G",
        "outputId": "75694790-255f-40d4-e5e8-d2b3e9051c01"
      },
      "outputs": [],
      "source": [
        "# Assign the class with the minimum distance as the predicted class\n",
        "y_pred = np.argmin(Prediction, axis=1)\n",
        "# Check the shape of the prediction\n",
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkRC1GcurOLd"
      },
      "outputs": [],
      "source": [
        "# Replace every occurrence of 2 with 1 for binary prediction\n",
        "y_binary = np.where(y_pred == 2, 1, y_pred)\n",
        "y_test_binary = np.where(y_test_encoded == 2, 1, y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ayUe3xBzqlgF",
        "outputId": "c6b30f28-f578-4ad9-ff0b-a6575fd0c79a"
      },
      "outputs": [],
      "source": [
        "# Visualize model performance\n",
        "confusion_mtx = confusion_matrix(y_test_binary, y_binary, normalize='true')\n",
        "\n",
        "# plot the confusion matrix\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='.2f')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test_binary, y_binary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BguUbCjV_YB2"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/AI_project'\n",
        "\n",
        "# Save the model\n",
        "model.save(save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-TN9rKvunAXF"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
