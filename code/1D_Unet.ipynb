{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TN9rKvunAXF"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with open('cleaned_128', 'rb') as f:\n",
        "    cleaned_128 = pkl.load(f)\n",
        "with open('cleaned_down', 'rb') as f:\n",
        "    cleaned_down = pkl.load(f)\n",
        "with open('clean_peak_128', 'rb') as f:\n",
        "    clean_peak_128 = pkl.load(f)\n",
        "with open('clean_peak_down', 'rb') as f:\n",
        "    clean_peak_down = pkl.load(f)\n",
        "with open('clean_label_128', 'rb') as f:\n",
        "    clean_label_128 = pkl.load(f)\n",
        "with open('clean_label_down', 'rb') as f:\n",
        "    clean_label_down = pkl.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbjCnMyM6iNO"
      },
      "source": [
        "# Build Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1o-6Q_DYtyK"
      },
      "outputs": [],
      "source": [
        "# Define a Patient class so that train-validation-test split can be performed easily later\n",
        "class Patient:\n",
        "    def __init__(self,\n",
        "                 sequences=None, masks=None,\n",
        "                 sequences_labels=None, sequences_peaks=None):\n",
        "\n",
        "        # Segmented beats and masks\n",
        "        self.sequences = sequences if sequences is not None else []\n",
        "        self.masks = masks if masks is not None else []\n",
        "        # Labels and peak locations\n",
        "        self.sequences_labels = sequences_labels if sequences_labels is not None else []\n",
        "        self.sequences_peaks = sequences_peaks if sequences_peaks is not None else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lcF2sxEYtyK"
      },
      "outputs": [],
      "source": [
        "# Initialize the patient instances as empty lists\n",
        "NUM_PATIENTS = len(cleaned_128) + len(cleaned_down)\n",
        "\n",
        "patient_instances = [Patient() for _ in range(NUM_PATIENTS)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNrebzeZ6osV"
      },
      "outputs": [],
      "source": [
        "def build_sequences(signal, peaks, labels, sampling_frequency, sequence_length):\n",
        "    sequence_length_samples = int(sequence_length * sampling_frequency)\n",
        "\n",
        "    sequences = []\n",
        "    corresponding_peaks = []\n",
        "    peak_labels = []\n",
        "    num_samples = len(signal)\n",
        "    num_sequences = int(np.ceil(num_samples / sequence_length_samples))\n",
        "\n",
        "    for j in range(num_sequences):\n",
        "        start_index = j * sequence_length_samples\n",
        "        end_index = min((j + 1) * sequence_length_samples, num_samples)\n",
        "\n",
        "        # Extract the sequence\n",
        "        sequence = signal[start_index:end_index]\n",
        "\n",
        "        # Pad the sequence if its duration is less than 30 seconds\n",
        "        padding = np.zeros(sequence_length_samples - len(sequence))\n",
        "        padded_sequence = np.concatenate((sequence, padding))\n",
        "\n",
        "        sequences.append(padded_sequence)\n",
        "\n",
        "        # Calculate corresponding peak position in the sequence\n",
        "        relative_peak_positions = peaks[(peaks >= start_index) & (peaks < end_index)] - start_index\n",
        "        corresponding_peaks.append(relative_peak_positions)\n",
        "\n",
        "        # Find indices of relative_peak_positions in the original peaks\n",
        "        peak_indices = np.where(np.isin(peaks, relative_peak_positions + start_index))[0]\n",
        "\n",
        "        # Assign the labels of the found peaks to the sequence\n",
        "        found_labels = labels[peak_indices]\n",
        "        peak_labels.append(found_labels)\n",
        "\n",
        "\n",
        "    return sequences, corresponding_peaks, peak_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE3n5EfN-Rwp"
      },
      "outputs": [],
      "source": [
        "def generate_mask_sequences(output_sequences, corresponding_peaks, labels, sampling_frequency):\n",
        "    mask_sequences = []\n",
        "\n",
        "    for i in range(len(output_sequences)):\n",
        "        sequence = output_sequences[i]\n",
        "        peaks = corresponding_peaks[i]\n",
        "        label = labels[i]\n",
        "\n",
        "        mask_sequence = np.zeros_like(sequence, dtype=int)\n",
        "\n",
        "        # Defining the area of each beat for masks creation\n",
        "        before_samples = 15\n",
        "        after_samples = 25\n",
        "\n",
        "        # Set mask values based on beat type\n",
        "        for j in range(len(peaks)):\n",
        "            if np.any(label[j] == \"N\"):\n",
        "                mask_sequence[peaks[j] - before_samples : peaks[j] + after_samples] = 1\n",
        "            elif np.any(label[j] == \"S\"):\n",
        "                mask_sequence[peaks[j] - before_samples : peaks[j] + after_samples] = 2\n",
        "            elif np.any(label[j] == \"V\"):\n",
        "                mask_sequence[peaks[j] - before_samples : peaks[j] + after_samples] = 3\n",
        "\n",
        "        mask_sequences.append(mask_sequence)\n",
        "\n",
        "    return mask_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfOKcBNfZvSX",
        "outputId": "9b6834bc-74c9-4e1d-a3fe-2252d83a444d"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "print(\"Build sequences of 128Hz signals...\")\n",
        "for i, patient_instance in tqdm.tqdm(enumerate(patient_instances[:len(cleaned_128)]), total=len(cleaned_128)):\n",
        "    # Build sequences of signal\n",
        "    sequences_128, sequences_peaks_128, sequences_labels_128 = build_sequences(cleaned_128[i], clean_peak_128[i], clean_label_128[i], 128, 25)\n",
        "    # Generate Masks for 128Hz\n",
        "    mask_sequences_128 = generate_mask_sequences(sequences_128, sequences_peaks_128, sequences_labels_128, 128)\n",
        "\n",
        "    # Store the sequences and masks in the patient instance\n",
        "    patient_instance.sequences = sequences_128\n",
        "    patient_instance.masks = mask_sequences_128\n",
        "    patient_instance.sequences_peaks = sequences_peaks_128\n",
        "    # Store the labels in the patient instance\n",
        "    patient_instance.sequences_labels = sequences_labels_128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XZKFKgofIUq",
        "outputId": "18fad6a8-d41c-4318-9499-79acb75efb6a"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "print(\"Build sequences of Downsampled signals...\")\n",
        "for i, patient_instance in tqdm.tqdm(enumerate(patient_instances[:len(cleaned_down)]), total=len(cleaned_down)):\n",
        "    # Build sequences of signal\n",
        "    sequences_down, sequences_peaks_down, sequences_labels_down = build_sequences(cleaned_down[i], clean_peak_down[i], clean_label_down[i], 128, 25)\n",
        "    # Generate Masks for Downsampled\n",
        "    mask_sequences_down = generate_mask_sequences(sequences_down, sequences_peaks_down, sequences_labels_down, 128)\n",
        "\n",
        "    # Store the sequences and masks in the patient instance\n",
        "    patient_instance.sequences = sequences_down\n",
        "    patient_instance.masks = mask_sequences_down\n",
        "    patient_instance.sequences_peaks = sequences_peaks_down\n",
        "    # Store the labels in the patient instance\n",
        "    patient_instance.sequences_labels = sequences_labels_down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "DdBxeK-gZRHl",
        "outputId": "7aa3da1c-96da-4547-8f14-9ddfdc17911d"
      },
      "outputs": [],
      "source": [
        "plt.plot(patient_instance.masks[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "LVAPxRk4YgYD",
        "outputId": "1328099e-3a00-4b0f-b52f-0f78d47413dd"
      },
      "outputs": [],
      "source": [
        "plt.plot(patient_instance.sequences[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nOedRuygjL-"
      },
      "source": [
        "# Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ApjZEbKhZFN",
        "outputId": "b0de79fa-9fe4-469d-a8fa-c5261ea0d309"
      },
      "outputs": [],
      "source": [
        "# Define a function to check class distribution\n",
        "def calculate_label_distribution(labels):\n",
        "  tot_count_n = 0\n",
        "  tot_count_s = 0\n",
        "  tot_count_v = 0\n",
        "  for idx in range(len(labels)):\n",
        "    counts_n = np.count_nonzero(labels[idx] == 'N')\n",
        "    counts_s = np.count_nonzero(labels[idx] == 'S')\n",
        "    counts_v = np.count_nonzero(labels[idx] == 'V')\n",
        "    tot_count_n += counts_n\n",
        "    tot_count_s += counts_s\n",
        "    tot_count_v += counts_v\n",
        "  return tot_count_n, tot_count_s, tot_count_v\n",
        "\n",
        "def calculate_class_distribution(patient_instances):\n",
        "    \"\"\"\n",
        "    Calculates the class distribution of the labels.\n",
        "\n",
        "    Args:\n",
        "        patient_instances (list): The list of patient instances.\n",
        "    \"\"\"\n",
        "    tot_count_n = 0\n",
        "    tot_count_s = 0\n",
        "    tot_count_v = 0\n",
        "    for patient in patient_instances:\n",
        "        count_n, count_s, count_v = calculate_label_distribution(patient.sequences_labels)\n",
        "        tot_count_n += count_n\n",
        "        tot_count_s += count_s\n",
        "        tot_count_v += count_v\n",
        "    print(f\"Label Distribution: {tot_count_n} N beats, {tot_count_s} S beats, {tot_count_v} V beats\")\n",
        "\n",
        "# Check class distribution\n",
        "calculate_class_distribution(patient_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPzg2lUBgddU",
        "outputId": "a676be92-6edb-47a7-9916-a578a4b0b795"
      },
      "outputs": [],
      "source": [
        "# Define a function to compute class proportions\n",
        "def calculate_class_proportions(patient_instances):\n",
        "    \"\"\"\n",
        "    Calculates the class proportions of the labels.\n",
        "\n",
        "    Args:\n",
        "        patient_instances (list): The list of patient instances.\n",
        "    \"\"\"\n",
        "    tot_count_n = 0\n",
        "    tot_count_s = 0\n",
        "    tot_count_v = 0\n",
        "    for patient in patient_instances:\n",
        "        count_n, count_s, count_v = calculate_label_distribution(patient.sequences_labels)\n",
        "        tot_count_n += count_n\n",
        "        tot_count_s += count_s\n",
        "        tot_count_v += count_v\n",
        "    n_ratio = tot_count_n / (tot_count_n + tot_count_v + tot_count_s)\n",
        "    v_ratio = tot_count_v / (tot_count_n + tot_count_v + tot_count_s)\n",
        "    s_ratio = tot_count_s / (tot_count_n + tot_count_v + tot_count_s)\n",
        "    print(f\"Label proportions: {round(n_ratio, 4)} N beats, {round(v_ratio, 4)} V beats, {round(s_ratio, 4)} S beats\")\n",
        "    return n_ratio, v_ratio, s_ratio\n",
        "\n",
        "# Check class proportions\n",
        "n_ratio, v_ratio, s_ratio = calculate_class_proportions(patient_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLKSZR8qg9WO",
        "outputId": "b733dd7e-0a7a-4221-dc0b-ea2bfadaf0ef"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initialize variables\n",
        "n_ratio_train = 0\n",
        "s_ratio_train = 0\n",
        "v_ratio_train = 0\n",
        "\n",
        "n_ratio_val = 0\n",
        "s_ratio_val = 0\n",
        "v_ratio_val = 0\n",
        "\n",
        "n_ratio_test = 0\n",
        "s_ratio_test = 0\n",
        "v_ratio_test = 0\n",
        "random_state = 999\n",
        "max_iterations = 100\n",
        "iteration = 0\n",
        "\n",
        "# Initialize variables for the best split\n",
        "best_diff = float('inf')\n",
        "best_split = None\n",
        "\n",
        "# Loop until desired conditions are met\n",
        "while((abs(n_ratio_train - n_ratio) > 0.001 or abs(s_ratio_train - s_ratio) > 0.001 or abs(v_ratio_train - v_ratio) > 0.001 or\n",
        "       abs(n_ratio_val - n_ratio) > 0.001 or abs(s_ratio_val - s_ratio) > 0.001 or abs(v_ratio_val - v_ratio) > 0.001 or\n",
        "       abs(n_ratio_test - n_ratio) > 0.001 or abs(s_ratio_test - s_ratio) > 0.001 or abs(v_ratio_test - v_ratio) > 0.001) and iteration < max_iterations):\n",
        "\n",
        "    # Split the data into train, validation and test sets\n",
        "    X_train_val, X_test = train_test_split(patient_instances, test_size=0.15, random_state=random_state)\n",
        "    X_train, X_val = train_test_split(X_train_val, test_size=len(X_test), random_state=random_state)\n",
        "\n",
        "    # Check label distribution in train set\n",
        "    print(\"Train set:\")\n",
        "    calculate_class_distribution(X_train)\n",
        "    n_ratio_train, v_ratio_train, s_ratio_train = calculate_class_proportions(X_train)\n",
        "\n",
        "    # Check label distribution in validation set\n",
        "    print(\"Validation set:\")\n",
        "    calculate_class_distribution(X_val)\n",
        "    n_ratio_val, v_ratio_val, s_ratio_val = calculate_class_proportions(X_val)\n",
        "\n",
        "    # Check label distribution in test set\n",
        "    print(\"Test set:\")\n",
        "    calculate_class_distribution(X_test)\n",
        "    n_ratio_test, v_ratio_test, s_ratio_test = calculate_class_proportions(X_test)\n",
        "\n",
        "    # Calculate the total difference between the ratios\n",
        "    total_diff = abs(n_ratio_train - n_ratio) + abs(s_ratio_train - s_ratio) + abs(v_ratio_train - v_ratio) + \\\n",
        "                abs(n_ratio_val - n_ratio) + abs(s_ratio_val - s_ratio) + abs(v_ratio_val - v_ratio) + \\\n",
        "                abs(n_ratio_test - n_ratio) + abs(s_ratio_test - s_ratio) + abs(v_ratio_test - v_ratio)\n",
        "\n",
        "    # If this split is better than the previous best, update the best split\n",
        "    if total_diff < best_diff:\n",
        "        best_diff = total_diff\n",
        "        best_split = (X_train, X_val, X_test)\n",
        "\n",
        "    random_state += 1\n",
        "    iteration += 1\n",
        "\n",
        "# After the loop, best_split contains the best split found\n",
        "if(iteration >= max_iterations):\n",
        "    print(\"Max iterations reached\")\n",
        "    X_train, X_val, X_test = best_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhUkN8-ZqeiZ",
        "outputId": "24022217-fd3b-4384-a20c-11938c06ae6f"
      },
      "outputs": [],
      "source": [
        "# Check the class proportions of the sets\n",
        "print(\"Train set:\")\n",
        "calculate_class_proportions(X_train)\n",
        "print(\"Validation set:\")\n",
        "calculate_class_proportions(X_val)\n",
        "print(\"Test set:\")\n",
        "calculate_class_proportions(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMuzK6Kfqh13",
        "outputId": "b3470534-263c-4db7-e541-c5baac1f0e08"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build train, validation and test sets\n",
        "X_train_seq = [sequence for patient in X_train for sequence in patient.sequences]\n",
        "X_val_seq = [sequence for patient in X_val for sequence in patient.sequences]\n",
        "X_test_seq = [sequence for patient in X_test for sequence in patient.sequences]\n",
        "\n",
        "# Build train, validation and test labels\n",
        "y_train = [mask for patient in X_train for mask in patient.masks]\n",
        "y_val = [mask for patient in X_val for mask in patient.masks]\n",
        "y_test = [mask for patient in X_test for mask in patient.masks]\n",
        "\n",
        "# Check dimensionality of train, validation and test sets\n",
        "print(f\"Train dim.: {len(X_train_seq)}\")\n",
        "print(f\"Validation dim.: {len(X_val_seq)}\")\n",
        "print(f\"Test dim.: {len(X_test_seq)}\")\n",
        "\n",
        "# Check dimensionality of labels\n",
        "print(\"-> Labels\")\n",
        "print(f\"Train labels dim.: {len(y_train)}\")\n",
        "print(f\"Validation labels dim.: {len(y_val)}\")\n",
        "print(f\"Test labels dim.: {len(y_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TjMixLfBWPX",
        "outputId": "c1986e15-9b39-4284-e42e-d808e26f4364"
      },
      "outputs": [],
      "source": [
        "X_train = tf.convert_to_tensor(X_train_seq)\n",
        "X_val = tf.convert_to_tensor(X_val_seq)\n",
        "X_test = tf.convert_to_tensor(X_test_seq)\n",
        "\n",
        "print(X_train.shape), print(X_val.shape), print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxvNRWsJxSt_"
      },
      "outputs": [],
      "source": [
        "y_train_encoded = to_categorical(y_train, num_classes=4)\n",
        "y_val_encoded = to_categorical(y_val, num_classes=4)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxNb9EElO7sw"
      },
      "source": [
        "# 1D Unet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6pZSGV8qVdE"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuXLbfvpO6LY",
        "outputId": "1e9b1cc3-0eb6-40b0-bcf6-3bf674fab289"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, filters, kernel_size=9, dilation_rate=3, strides=1):\n",
        "    x = Conv1D(filters, kernel_size, strides=strides, padding='same', dilation_rate=dilation_rate)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def unet(input_shape, num_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Contracting Path (Encoder)\n",
        "    conv1 = conv_block(inputs, 64)\n",
        "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = conv_block(pool1, 128)\n",
        "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "    conv3 = conv_block(pool2, 256)\n",
        "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
        "\n",
        "    conv4 = conv_block(pool3, 512)\n",
        "    pool4 = MaxPooling1D(pool_size=2)(conv4)\n",
        "\n",
        "    # Bottleneck\n",
        "    bottleneck = conv_block(pool4, 1024)\n",
        "\n",
        "    # Expanding Path (Decoder)\n",
        "    up5 = UpSampling1D(size=2)(bottleneck)\n",
        "    concat5 = concatenate([up5, conv4], axis=-1)\n",
        "    conv5 = conv_block(concat5, 512)\n",
        "\n",
        "    up6 = UpSampling1D(size=2)(conv5)\n",
        "    concat6 = concatenate([up6, conv3], axis=-1)\n",
        "    conv6 = conv_block(concat6, 256)\n",
        "\n",
        "    up7 = UpSampling1D(size=2)(conv6)\n",
        "    concat7 = concatenate([up7, conv2], axis=-1)\n",
        "    conv7 = conv_block(concat7, 128)\n",
        "\n",
        "    up8 = UpSampling1D(size=2)(conv7)\n",
        "    concat8 = concatenate([up8, conv1], axis=-1)\n",
        "    conv8 = conv_block(concat8, 64)\n",
        "\n",
        "    # Output Layer\n",
        "    output = Conv1D(4, kernel_size=1, activation='sigmoid')(conv8)\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the input shape and create the model\n",
        "input_shape = (3200, 1)\n",
        "\n",
        "# Define your model\n",
        "model = unet(input_shape, 4)\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ohB2PoI35tK"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as tfk\n",
        "import tensorflow as tf\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=[tf.keras.metrics.Recall(class_id=0),\n",
        "                                                                                                       tf.keras.metrics.Recall(class_id=1),\n",
        "                                                                                                       tf.keras.metrics.Recall(class_id=2),\n",
        "                                                                                                       tf.keras.metrics.Recall(class_id=3),\n",
        "                                                                                                       tf.keras.metrics.Precision(class_id=0),\n",
        "                                                                                                       tf.keras.metrics.Precision(class_id=1),\n",
        "                                                                                                       tf.keras.metrics.Precision(class_id=2),\n",
        "                                                                                                       tf.keras.metrics.Precision(class_id=3)\n",
        "                                                                                                        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djb9AkmJ5CK-"
      },
      "outputs": [],
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    mode='min',\n",
        "    min_delta=1e-7,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch = 20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcMLf3SvFxhe"
      },
      "outputs": [],
      "source": [
        "y_train_tensor = tf.convert_to_tensor(y_train)\n",
        "y_val_tensor = tf.convert_to_tensor(y_val)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-lNJE2Ywrdg",
        "outputId": "76705da5-758b-4f1e-f913-983101b2a238"
      },
      "outputs": [],
      "source": [
        "# Calculation of class weights\n",
        "w = np.sum(y_train_encoded,axis=(0,1))\n",
        "print(w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6oPWngbwrdh",
        "outputId": "738f7161-7f2b-46d0-b74a-8286f6eea44b"
      },
      "outputs": [],
      "source": [
        "somma = 0\n",
        "weights = {}\n",
        "weights_norm = {}\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "  weights[i] = sum(w)/w[i]\n",
        "  somma += weights[i]\n",
        "print(weights)\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "  weights_norm[i]=weights[i]/somma\n",
        "#compute weights for each label to use during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxNufF_PAIbn",
        "outputId": "68d73004-9901-4c50-ec9c-4029c4b37ad3"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train_encoded,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val_encoded),\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight = weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph59Fp0g_FAz",
        "outputId": "27941ce9-b97f-4df6-b049-09bb7462a5a1"
      },
      "outputs": [],
      "source": [
        "# Get predictions for test data\n",
        "predictions = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btDHhO6w-JdH"
      },
      "outputs": [],
      "source": [
        "y_test_np = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "hQdE8uot99TK",
        "outputId": "3433b054-8b3f-46ce-8ba2-92d2d0d0030c"
      },
      "outputs": [],
      "source": [
        "# Aggregate predictions along the sequence axis (axis=1)\n",
        "aggregated_predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "# Flatten true labels and aggregated predictions\n",
        "true_labels_flat = y_test_np.flatten()\n",
        "aggregated_predictions_flat = aggregated_predictions.flatten()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels_flat, aggregated_predictions_flat, normalize='true')\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True)#, fmt='.2f' if normalize else 'd', cmap='Blues')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5wTlaVl99TK",
        "outputId": "b534530d-3106-4026-8d7d-a85c62ee2578"
      },
      "outputs": [],
      "source": [
        "# Compute accuracy\n",
        "accuracy = accuracy_score(true_labels_flat, aggregated_predictions_flat)\n",
        "\n",
        "# Compute precision\n",
        "precision = precision_score(true_labels_flat, aggregated_predictions_flat, average='macro')\n",
        "\n",
        "# Compute recall\n",
        "recall = recall_score(true_labels_flat, aggregated_predictions_flat, average='macro')\n",
        "\n",
        "# Compute F1 score\n",
        "f1 = f1_score(true_labels_flat, aggregated_predictions_flat, average='macro')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "_JWFW0HXAxBs",
        "outputId": "100daf1f-fbb3-4e84-f424-c76539d16c57"
      },
      "outputs": [],
      "source": [
        "plt.plot(y_test[17])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Y_rXpkOHAjnE",
        "outputId": "0a030fb7-8cc3-4f81-f484-4dd147a9d850"
      },
      "outputs": [],
      "source": [
        "plt.plot(predictions[17])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7O2h1YgFtAG"
      },
      "outputs": [],
      "source": [
        "# Define thresholds for each label to do a post processing\n",
        "thresholds = [0.8, 0.4, 0.4]\n",
        "\n",
        "# Create a new array for the post-processed predictions\n",
        "post_processed_predictions = np.zeros_like(np.zeros(predictions.shape))\n",
        "\n",
        "# Iterate through each sample\n",
        "for sample_idx in range(predictions.shape[0]):\n",
        "    for idx in range(predictions.shape[1]):\n",
        "        # Check for the 4th label\n",
        "        if predictions[sample_idx, idx, 3] > thresholds[2]:\n",
        "            post_processed_predictions[sample_idx, max(0, idx-10):min(predictions.shape[1], idx+15)] = 3\n",
        "        # Check for the 3rd label\n",
        "        elif predictions[sample_idx, idx, 2] > thresholds[1]:\n",
        "            post_processed_predictions[sample_idx, max(0, idx-10):min(predictions.shape[1], idx+15)] = 2\n",
        "        # Check for the 2nd label\n",
        "        elif predictions[sample_idx, idx, 1] > thresholds[0]:\n",
        "            post_processed_predictions[sample_idx, max(0, idx-10):min(predictions.shape[1], idx+15)] = 1\n",
        "        else:\n",
        "            post_processed_predictions[sample_idx, idx] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "zNVWDtJICWWY",
        "outputId": "f537340a-c162-4d68-f013-329c6a7def7d"
      },
      "outputs": [],
      "source": [
        "plt.plot(post_processed_predictions[17])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
